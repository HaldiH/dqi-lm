model:
  name: "unsloth/gpt-oss-20b-BF16"
  max_seq_length: 4096
  load_in_4bit: false

lora:
  r: 64
  lora_alpha: 32
  lora_dropout: 0
  target_modules:
    [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj",
      "gate_proj",
      "up_proj",
      "down_proj",
    ]

training:
  output_dir: "outputs/gpt-oss-20b-bf16_finetuned"
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 8
  warmup_ratio: 0.1
  max_steps: 300
  learning_rate: 1.0e-4
  logging_steps: 20
  eval_steps: 30
  save_steps: 75
  save_total_limit: 3
  load_best_model_at_end: false
  metric_for_best_model: "eval_loss"
  save_safetensors: true
  resume_from_checkpoint: false
  weight_decay: 0.01
  max_grad_norm: 0.3
  tf32: true
  dataloader_num_workers: 4
  seed: 3407
  optim: "adamw_torch"
  gradient_checkpointing: true
  lr_scheduler_type: "cosine"
  packing: true
  neftune_noise_alpha: 5

wandb:
  project: "dqi-justification"
  run_name: "gpt-oss-20b-bf16"

# Model publishing options (optional)
publish:
  enabled: false # Set to true to enable publishing
  
  # Publish to HuggingFace Hub
  huggingface:
    enabled: false
    repo_id: "username/gpt-oss-20b-dqi-justification" # Your HuggingFace repo ID
    private: false # Set to true for private repos
    commit_message: "Upload finetuned GPT-OSS 20B BF16 model"
    # token: "" # Optional: Can also use HF_TOKEN environment variable
  
  # Publish to WandB as artifact
  wandb:
    enabled: false
    artifact_name: "gpt-oss-20b-bf16-dqi-finetuned"
    artifact_type: "model"
    description: "GPT-OSS 20B BF16 finetuned on DQI justification task"
    metadata:
      task: "text-classification"
      framework: "unsloth"

data:
  raw_debates_dir: "data/raw/hein-daily"
  merged_debates_path: "data/clean/merged_debates.csv"
  input_path: "data/raw/USfinal-clean.csv"
  train_path: "data/clean/train.csv"
  val_path: "data/clean/val.csv"
  test_path: "data/clean/test.csv"
  processed_train_path: "data/processed_train.jsonl"
  processed_val_path: "data/processed_val.jsonl"
  processed_test_path: "data/processed_test.jsonl"
  # CSV column mapping
  col_label: "Justification-level" # Name of the column containing the score (0-4)
  col_speech: "speech" # Name of the column containing the text to analyze
  labels: [0, 1, 2, 3, 4]

evaluation:
  results_dir: "results/gpt-oss-20b-bf16_finetuned"

prompts:
  system_prompt_path: "prompts/justification_criteria.txt" # Path to your text file
